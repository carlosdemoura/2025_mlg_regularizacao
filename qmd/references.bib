@article{lasso,
  author       = {Robert Tibshirani},
  title        = {Regression Shrinkage and Selection via the Lasso},
  journal      = {Journal of the Royal Statistical Society. Series B (Methodological)},
  volume       = {58},
  number       = {1},
  pages        = {267--288},
  year         = {1996},
  doi          = {10.1111/j.2517-6161.1996.tb02080.x},
  url          = {https://www.jstor.org/stable/2346178}
}

@article{en,
  author       = {Hui Zou and Trevor Hastie},
  title        = {Regularization and Variable Selection via the Elastic Net},
  journal      = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},
  volume       = {67},
  number       = {2},
  pages        = {301--320},
  year         = {2005},
  doi          = {10.1111/j.1467-9868.2005.00503.x},
  url          = {https://www.jstor.org/stable/3647580}
}

@article{ridge,
  author       = {Arthur E. Hoerl and Robert W. Kennard},
  title        = {Ridge Regression: Biased Estimation for Nonorthogonal Problems},
  journal      = {Technometrics},
  volume       = {12},
  number       = {1},
  pages        = {55--67},
  year         = {1970},
  doi          = {10.1080/00401706.1970.10488634},
  url          = {https://www.jstor.org/stable/1267351}
}

@book{islr,
  author       = {Gareth James and Daniela Witten and Trevor Hastie and Robert Tibshirani},
  title        = {An Introduction to Statistical Learning: With Applications in R},
  series       = {Springer Texts in Statistics},
  year         = {2021},
  publisher    = {Springer},
  doi          = {10.1007/978-1-0716-1418-1},
  url          = {https://link.springer.com/book/10.1007/978-1-0716-1418-1}
}

@book{tmwr,
  author    = {Max Kuhn and Julia Silge},
  title     = {Tidy Modeling with R},
  year      = {2022},
  publisher = {O'Reilly Media},
  url       = {https://www.tmwr.org/}
}

@manual{R,
  title        = {R: A Language and Environment for Statistical Computing},
  author       = {{R Core Team}},
  organization = {R Foundation for Statistical Computing},
  address      = {Vienna, Austria},
  year         = {2024},
  url          = {https://www.r-project.org/}
}

@manual{glmnet,
  title        = {glmnet: Lasso and Elastic-Net Regularized Generalized Linear Models},
  author       = {Jerome Friedman and Trevor Hastie and Rob Tibshirani and others},
  organization = {Stanford University},
  year         = {2025},
  note         = {R package version 4.1-10},
  url          = {https://glmnet.stanford.edu/}
}

@article{en_glm,
  author  = {J. Kenneth Tay and Balasubramanian Narasimhan and Trevor Hastie},
  title   = {Elastic Net Regularization Paths for All Generalized Linear Models},
  journal = {Journal of Statistical Software},
  volume  = {106},
  number  = {1},
  year    = {2023},
  pages   = {1--31},
  doi     = {10.18637/jss.v106.i01},
  url     = {https://www.jstatsoft.org/article/view/v106i01}
}

@article{en_glm2,
 title={Regularization Paths for Generalized Linear Models via Coordinate Descent},
 volume={33},
 url={https://www.jstatsoft.org/index.php/jss/article/view/v033i01},
 doi={10.18637/jss.v033.i01},
 abstract={We develop fast algorithms for estimation of generalized linear models with convex penalties. The models include linear regression, two-class logistic regression, and multi- nomial regression problems while the penalties include ℓ&amp;lt;sub&amp;gt;1&amp;lt;/sub&amp;gt; (the lasso), ℓ&amp;lt;sub&amp;gt;2&amp;lt;/sub&amp;gt; (ridge regression) and mixtures of the two (the elastic net). The algorithms use cyclical coordinate descent, computed along a regularization path. The methods can handle large problems and can also deal efficiently with sparse features. In comparative timings we find that the new algorithms are considerably faster than competing methods.},
 number={1},
 journal={Journal of Statistical Software},
 author={Friedman, Jerome H. and Hastie, Trevor and Tibshirani, Rob},
 year={2010},
 pages={1–22}
}