# Sobre {.unnumbered}

::: {style="text-align: right"}
"Eu tô te explicando<br>
Pra te confundir<br>
Eu tô te confundindo<br>
Pra te esclarecer"<br>
Tom Zé
:::

Este é o [material auxiliar](https://github.com/carlosdemoura/2025_mlg_regularizacao) da apresentação do trabalho final do curso de Modelos Lineares Generalizados (MLGs) (DEST-UFMG, 2025/2).
O tema é regularização em MLGs, em específico os métodos de regularização ridge, lasso e elastic net.
Este [quarto book](https://quarto.org/) está dividido da seguinte forma:

* Definição de regularização e apresentação dos métodos de shrinkage, com exemplos de regressão normal;
* Estimação dos parâmetros em MLG com penalização;
* Tunagem dos parâmetros de regularização;
* Exemplo prático com dados reais no R.

Referências bibliográficas importantes que foram usadas para a feitura desse trabalho são citadas ao final do documento.

Alguns pacotes que usaremos estão abaixo listados.

```{r}
#| eval: false
if (!{"pak" %in% rownames(installed.packages())}) install.packages("pak")

pak::pak(c("matrixcalc", "glmnet", "tidyverse", "mvtnorm", "ggplot2"))
```

## Licença ![CC BY 4.0](https://licensebuttons.net/l/by/4.0/88x31.png)

Este trabalho está licenciado sob a licença [Creative Commons Atribuição 4.0 Internacional (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/deed.pt-br).

## Motivação

Porquê fazer seleção de modelos?

* Com o advento da big data, cada vez mais aparecem problemas de regressão com muitas variáveis;
* Muitas variáveis podem estar altamente correlacionadas de modo que elas dizem a mesma coisa sobre o problema: precisamos de uma técnica para selecionar variáveis (preferência por modelos parcimoniosos);
* Se há muitas covariáveis correlacionadas, os modelos de estimação convencionais podem ter problemas e confundir a origem dos efeitos de regressão (falta de acurácia);
* A inclusão de muitas covariáveis no modelo tem o efeito conhecido de aumento da variância, fazendo com que as previsões sejam mais incertas.

Porquê regularizar coeficientes é uma boa ideia?

A regularização - _regularization_ ou _shrinkage_ (diminuição) em inglês - de coeficientes é feita ajustando-se um modelo com todos os coeficientes possíveis, mas há algum mecanismo que que dificulta fazer com que todos eles possam estar longe de zero.
Por isso os coeficientes diminuem (_honey, i shrunk the kids!_) em relação à estimação de mínimos quadrados ordinária. Em alguns casos eles são estimados como zero mesmo!
Isso tem o efeito de reduzir a variância das estimações e produzir modelos mais parcimoniosos.
