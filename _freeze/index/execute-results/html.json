{
  "hash": "3e0affb2e4c6798a61f1b884a6653790",
  "result": {
    "engine": "knitr",
    "markdown": "# Sobre {.unnumbered}\n\n::: {style=\"text-align: right\"}\n\"Eu tô te explicando<br>\nPra te confundir<br>\nEu tô te confundindo<br>\nPra te esclarecer\"<br>\nTom Zé\n:::\n\nEste é o [material auxiliar](https://github.com/carlosdemoura/2025_mlg_regularizacao) da apresentação do trabalho final do curso de Modelos Lineares Generalizados (MLGs) (DEST-UFMG, 2025/2).\nO tema é regularização em MLGs, em específico os métodos de regularização ridge, lasso e elastic net.\nEste [quarto book](https://quarto.org/) está dividido da seguinte forma:\n\n* Definição de regularização e apresentação dos métodos de shrinkage, com exemplos de regressão normal;\n* Estimação dos parâmetros em MLG com penalização;\n* Tunagem dos parâmetros de regularização;\n* Exemplo prático com dados reais no R.\n\nReferências bibliográficas importantes que foram usadas para a feitura desse trabalho são citadas ao final do documento.\n\nAlguns pacotes que usaremos estão abaixo listados.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!{\"pak\" %in% rownames(installed.packages())}) install.packages(\"pak\")\n\npak::pak(c(\"matrixcalc\", \"glmnet\", \"tidyverse\", \"mvtnorm\", \"ggplot2\", \"boot\"))\n```\n:::\n\n\n## Licença\n\nEste trabalho está licenciado sob a licença [Creative Commons Atribuição 4.0 Internacional (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/deed.pt-br).\n\n![CC BY 4.0](https://licensebuttons.net/l/by/4.0/88x31.png)\n\n## Motivação\n\nPorquê fazer seleção de modelos?\n\n* Com o advento da big data, cada vez mais aparecem problemas de regressão com muitas variáveis;\n* Muitas variáveis podem estar altamente correlacionadas de modo que elas dizem a mesma coisa sobre o problema: precisamos de uma técnica para selecionar variáveis (preferência por modelos parcimoniosos);\n* Se há muitas covariáveis correlacionadas, os modelos de estimação convencionais podem ter problemas e confundir a origem dos efeitos de regressão (falta de acurácia);\n* A inclusão de muitas covariáveis no modelo tem o efeito conhecido de aumento da variância, fazendo com que as previsões sejam mais incertas.\n\nPorquê regularizar coeficientes é uma boa ideia?\n\nA regularização - _regularization_ ou _shrinkage_ (diminuição) em inglês - de coeficientes é feita ajustando-se um modelo com todos os coeficientes possíveis, mas há algum mecanismo que que dificulta fazer com que todos eles possam estar longe de zero.\nPor isso os coeficientes diminuem (_honey, i shrunk the kids!_) em relação à estimação de mínimos quadrados ordinária. Em alguns casos eles são estimados como zero mesmo!\nIsso tem o efeito de reduzir a variância das estimações e produzir modelos mais parcimoniosos.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}